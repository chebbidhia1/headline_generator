{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "headline_generator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tvuHYm5LVYF"
      },
      "source": [
        "## Objectives\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq2lK0jeLPsJ"
      },
      "source": [
        "* Prepare sequence data to use in a recurrent neural network (RNN)\r\n",
        "* Build and train a model to perform word prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcg_hf_oLj0s"
      },
      "source": [
        "import os \r\n",
        "import pandas as pd\r\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI-zPUzK5l_J",
        "outputId": "bd94f2ab-9b74-4291-b047-23c5c891a991"
      },
      "source": [
        "all_headlines = []\r\n",
        "for filename in os.listdir():\r\n",
        "    if 'Articles' in filename:\r\n",
        "        # Read in all all the data from the CSV file\r\n",
        "        headlines_df = pd.read_csv(filename)\r\n",
        "        # Add all of the headlines to our list\r\n",
        "        all_headlines.extend(list(headlines_df.headline.values))\r\n",
        "len(all_headlines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9335"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bazfJppP7kJQ",
        "outputId": "5e1d8130-bb83-408c-a45e-55782755c3c1"
      },
      "source": [
        "all_headlines[52]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The Phones We Love Too Much'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NPctIX_7bnC",
        "outputId": "9d8fc769-b2d6-4287-e673-966e73982f98"
      },
      "source": [
        "# Remove all headlines with the value of \"Unknown\"\r\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\r\n",
        "len(all_headlines)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wQOGwZS7w2x",
        "outputId": "27dcc6d4-9d0d-4691-9745-bfa774918dbc"
      },
      "source": [
        "all_headlines[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My Beijing: The Sacred City',\n",
              " '6 Million Riders a Day, 1930s Technology',\n",
              " 'Seeking a Cross-Border Conference',\n",
              " 'Questions for: ‘Despite the “Yuck Factor,” Leeches Are Big in Russian Medicine’',\n",
              " 'Who Is a ‘Criminal’?',\n",
              " 'An Antidote to Europe’s Populism',\n",
              " 'The Cost of a Speech',\n",
              " 'Degradation of the Language',\n",
              " 'On the Power of Being Awful',\n",
              " 'Trump Garbles Pitch on a Revised Health Bill',\n",
              " 'What’s Going On in This Picture? | May 1, 2017',\n",
              " 'When Patients Hit a Medical Wall',\n",
              " 'For Pregnant Women, Getting Serious About Whooping Cough',\n",
              " 'New York City Transit Reporter in Wonderland: Riding the London Tube',\n",
              " 'How to Cut an Avocado Without Cutting Yourself',\n",
              " 'In Fictional Suicide, Health Experts Say They See a Real Cause for Alarm',\n",
              " 'Claims of Liberal Media Bias Hit ESPN, Too',\n",
              " 'Is the dream in Australia crumbling?',\n",
              " 'Police in Texas Change Account in Officer’s Fatal Shooting of 15-Year-Old',\n",
              " 'Most Adults Favor Sex Ed. Most Students Don’t Get It.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbAHE6eQL9wp"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sqjmnlqbQfa"
      },
      "source": [
        "This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuDgUcR58Qm4",
        "outputId": "016711ab-cfc0-4b88-b7f1-fbb5568384b7"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "\r\n",
        "# Tokenize the words in our headlines\r\n",
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(all_headlines)\r\n",
        "total_words = len(tokenizer.word_index) + 1\r\n",
        "print('Total words: ', total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total words:  11753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2tvnzxX8Qtf",
        "outputId": "12aefe51-8361-4bbc-8509-1dcd6cb813a7"
      },
      "source": [
        "# Print a subset of the word_index dictionary created by Tokenizer\r\n",
        "subset_dict = {key: value for key, value in tokenizer.word_index.items() \\\r\n",
        "               if key in ['a','man','a','plan','a','canal','panama']}\r\n",
        "print(subset_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 2, 'plan': 83, 'man': 140, 'panama': 2733, 'canal': 6748}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCIXnQXc9LeF",
        "outputId": "5a3ff61a-7154-4e9d-fe73-b93fb36da509"
      },
      "source": [
        "tokenizer.texts_to_sequences(['a','man','a','plan','a','canal','panama'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2], [140], [2], [83], [2], [6748], [2733]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg5rdTZHbhN8"
      },
      "source": [
        "## Creating Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00VZ4LAt9LoI",
        "outputId": "9d08f0d2-faa6-4148-f5b0-28a1c800dd46"
      },
      "source": [
        "# Convert data to sequence of tokens \r\n",
        "input_sequences = []\r\n",
        "for line in all_headlines:\r\n",
        "    # Convert our headline into a sequence of tokens\r\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\r\n",
        "    \r\n",
        "    # Create a series of sequences for each headline\r\n",
        "    for i in range(1, len(token_list)):\r\n",
        "        partial_sequence = token_list[:i+1]\r\n",
        "        input_sequences.append(partial_sequence)\r\n",
        "\r\n",
        "print(tokenizer.sequences_to_texts(input_sequences[:5]))\r\n",
        "input_sequences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['my beijing', 'my beijing the', 'my beijing the sacred', 'my beijing the sacred city', '6 million']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[53, 1617],\n",
              " [53, 1617, 1],\n",
              " [53, 1617, 1, 1993],\n",
              " [53, 1617, 1, 1993, 126],\n",
              " [127, 347]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycLIk-CEbxpA"
      },
      "source": [
        "## Padding Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64cO_u9H9Lsx",
        "outputId": "046f100f-056d-4483-c91f-daae79f17d68"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# Determine max sequence length\r\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\r\n",
        "\r\n",
        "# Pad all sequences with zeros at the beginning to make them all max length\r\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\r\n",
        "len(input_sequences[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nse99iCYcJpl"
      },
      "source": [
        "## Creating Predictors and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQPemDIu-8bM",
        "outputId": "c99f312f-e5f8-4980-c187-cf89ff39b57b"
      },
      "source": [
        "# Predictors are every word except the last\r\n",
        "predictors = input_sequences[:,:-1]\r\n",
        "# Labels are the last word\r\n",
        "labels = input_sequences[:,-1]\r\n",
        "labels[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1617,    1, 1993,  126,  347], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elXg6u6HcUot"
      },
      "source": [
        "these targets are categorical. We are predicting one word out of our possible total vocabulary. Instead of the network predicting scalar numbers, we will have it predict binary categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tsuCbMN9yZ"
      },
      "source": [
        "from tensorflow.keras import utils\n",
        "\n",
        "labels = utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSWzMBkV_1K8",
        "outputId": "9adfe7eb-fd57-4b69-d718-a9adc250ee34"
      },
      "source": [
        "len(labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11753"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq2WJFqUcmVs"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1d609Ih_7u0"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "\r\n",
        "# Input is max sequence length - 1, as we've removed the last word for the label\r\n",
        "input_len = max_sequence_len - 1 \r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# Add input embedding layer\r\n",
        "model.add(Embedding(total_words, 10, input_length=input_len))\r\n",
        "\r\n",
        "# Add LSTM layer with 100 units\r\n",
        "model.add(LSTM(100))\r\n",
        "model.add(Dropout(0.1))\r\n",
        "\r\n",
        "# Add output layer\r\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVp4LZE8CgUU",
        "outputId": "3ed95119-d2b8-405e-9ef9-9775e14f1de7"
      },
      "source": [
        "model.summary()\r\n",
        "#num_params = g × [h(h+i) + h]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 27, 10)            117530    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11753)             1187053   \n",
            "=================================================================\n",
            "Total params: 1,348,983\n",
            "Trainable params: 1,348,983\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "incQGSd0dEvx"
      },
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngWZ_G07Jgic"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I8_EmTxJxJy",
        "outputId": "528a6646-ea45-45c0-ef1b-6c2af4cc51ae"
      },
      "source": [
        "model.fit(predictors, labels, epochs=30, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1666/1666 [==============================] - 87s 51ms/step - loss: 8.0492\n",
            "Epoch 2/30\n",
            "1666/1666 [==============================] - 81s 49ms/step - loss: 7.4450\n",
            "Epoch 3/30\n",
            "1666/1666 [==============================] - 81s 49ms/step - loss: 7.2504\n",
            "Epoch 4/30\n",
            "1666/1666 [==============================] - 81s 48ms/step - loss: 7.0111\n",
            "Epoch 5/30\n",
            "1666/1666 [==============================] - 82s 49ms/step - loss: 6.7657\n",
            "Epoch 6/30\n",
            "1666/1666 [==============================] - 82s 49ms/step - loss: 6.5015\n",
            "Epoch 7/30\n",
            "1666/1666 [==============================] - 82s 49ms/step - loss: 6.2613\n",
            "Epoch 8/30\n",
            "1666/1666 [==============================] - 81s 49ms/step - loss: 6.0115\n",
            "Epoch 9/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 5.7670\n",
            "Epoch 10/30\n",
            "1666/1666 [==============================] - 81s 48ms/step - loss: 5.5549\n",
            "Epoch 11/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 5.3065\n",
            "Epoch 12/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 5.1122\n",
            "Epoch 13/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 4.9278\n",
            "Epoch 14/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 4.7348\n",
            "Epoch 15/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 4.5743\n",
            "Epoch 16/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 4.4032\n",
            "Epoch 17/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 4.2543\n",
            "Epoch 18/30\n",
            "1666/1666 [==============================] - 80s 48ms/step - loss: 4.1053\n",
            "Epoch 19/30\n",
            "1666/1666 [==============================] - 81s 48ms/step - loss: 3.9743\n",
            "Epoch 20/30\n",
            "1666/1666 [==============================] - 82s 49ms/step - loss: 3.8637\n",
            "Epoch 21/30\n",
            "1666/1666 [==============================] - 82s 49ms/step - loss: 3.7294\n",
            "Epoch 22/30\n",
            "1666/1666 [==============================] - 83s 50ms/step - loss: 3.6049\n",
            "Epoch 23/30\n",
            "1666/1666 [==============================] - 83s 50ms/step - loss: 3.4860\n",
            "Epoch 24/30\n",
            "1666/1666 [==============================] - 82s 49ms/step - loss: 3.4107\n",
            "Epoch 25/30\n",
            "1666/1666 [==============================] - 83s 50ms/step - loss: 3.3276\n",
            "Epoch 26/30\n",
            "1666/1666 [==============================] - 83s 50ms/step - loss: 3.2219\n",
            "Epoch 27/30\n",
            "1666/1666 [==============================] - 84s 50ms/step - loss: 3.1536\n",
            "Epoch 28/30\n",
            "1666/1666 [==============================] - 82s 49ms/step - loss: 3.0760\n",
            "Epoch 29/30\n",
            "1666/1666 [==============================] - 82s 49ms/step - loss: 2.9975\n",
            "Epoch 30/30\n",
            "1666/1666 [==============================] - 81s 49ms/step - loss: 2.9358\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc0c5dd0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULSx2G0BdQ95"
      },
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onh2_w93U1iz"
      },
      "source": [
        "def predict_next_token(seed_text):\r\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\r\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\r\n",
        "    prediction = model.predict_classes(token_list, verbose=0)\r\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuHSwmp5U_p7",
        "outputId": "051036e7-dcfc-48ea-af2f-bd744175faa0"
      },
      "source": [
        "prediction = predict_next_token(\"today in new york\")\r\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkqEqbDZVEZq",
        "outputId": "053b6428-28e7-4056-f6e4-9f51323354f1"
      },
      "source": [
        "tokenizer.sequences_to_texts([prediction])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2M8Uk-zd41w"
      },
      "source": [
        "## Generate New Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZUv9hoZVJlj"
      },
      "source": [
        "def generate_headline(seed_text, next_words=1):\r\n",
        "    for _ in range(next_words):\r\n",
        "        # Predict next token\r\n",
        "        prediction = predict_next_token(seed_text)\r\n",
        "        # Convert token to word\r\n",
        "        next_word = tokenizer.sequences_to_texts([prediction])[0]\r\n",
        "        # Add next word to the headline. This headline will be used in the next pass of the loop.\r\n",
        "        seed_text += \" \" + next_word\r\n",
        "    # Return headline as title-case\r\n",
        "    return seed_text.title()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyRDFezOVNfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7327fb4a-4572-4bce-86d0-e3458d92448e"
      },
      "source": [
        "seed_texts = [\r\n",
        "    'washington dc is',\r\n",
        "    'today in new york',\r\n",
        "    'the school district has',\r\n",
        "    'crime has become']\r\n",
        "for seed in seed_texts:\r\n",
        "    print(generate_headline(seed, next_words=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Washington Dc Is Falling But Not Levels Is\n",
            "Today In New York And Sons Because 5 13\n",
            "The School District Has The Hunger Was Real Nightmare\n",
            "Crime Has Become A Nation 400 A Zebra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VwC8kQwVNoZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdIstFMEVNrr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}